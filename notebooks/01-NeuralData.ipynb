{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Data\n",
    "\n",
    "Check and explore the neural data for a single-neuron project,\n",
    "\n",
    "This notebook covers loading data, preparing metadata, getting micro-LFP data, and splitting channels ready for sorting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add local folder with `sort` module\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from sort import Paths\n",
    "from sort.io import load_object, save_to_h5file\n",
    "from sort.nsp import load_blackrock, check_blackrock_file_info\n",
    "from sort.channels import make_split_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths & Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the project path\n",
    "project_path = '/path/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of subjects\n",
    "subjects = Paths(project_path).get_files('recordings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set session information\n",
    "SESSION = {\n",
    "    'experiment' : 'XX',\n",
    "    'subject' : 'XX',\n",
    "    'session' : 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create database structure for the current file\n",
    "paths = Paths(project_path, **SESSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook settings\n",
    "SAVE_OUT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check session that is being loaded\n",
    "SESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Site Specific Settings\n",
    "\n",
    "If there is any site specific settings (for example, which files to load) these go here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Available Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of available neural data files\n",
    "data_files = data_paths.get_files('neural')\n",
    "data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available files by specific type\n",
    "nsp_files = paths.get_files('neural', select='XX')\n",
    "nsp_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data file to process\n",
    "data_file = nsp_files[0]\n",
    "data_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Electrodes Metadata File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the electrodes object\n",
    "electrodes = load_object(SESSION['subject'] + '.electrodes', paths.electrodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert and check the dataframe representation of the electrodes\n",
    "edf = electrodes.to_dataframe()\n",
    "edf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: load files from blackrock\n",
    "reader = load_blackrock(data_file, paths.neural, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Loaded Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channels (neural file)\n",
    "\n",
    "Check any channel information available in the NSP file(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Microwire Channel Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of micro channels\n",
    "n_micros = len(micro_chans)\n",
    "\n",
    "# Validate the expected number of channels\n",
    "assert len(probes) * 8 == n_micros\n",
    "\n",
    "# Check the number of probes / channels\n",
    "print('Data: {} probes ({} channels)'.format(len(probes), len(micro_chans)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set block and segment of interest\n",
    "block_ind = 0\n",
    "seg_ind = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check example data segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract an example data chunk - blackrock example\n",
    "data_chunk = reader.get_analogsignal_chunk(block_ind, seg_ind, 10*fs, 11*fs, channel_indexes=chi).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Channel Files\n",
    "\n",
    "Save out extracted channel data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_OUT:\n",
    "    \n",
    "    print('Extracting channel data for {}...'.format(SESSION['subject']))\n",
    "    for ch_name in micro_chans:\n",
    "                \n",
    "        channel_data = {\n",
    "            'data' : np.squeeze(reader.get_analogsignal_chunk(block_ind, seg_ind, channel_names=[ch_name])),\n",
    "            'sr' : fs, \n",
    "        }\n",
    "        \n",
    "        split_file_name = make_split_file_name(ch_name, site, edf)\n",
    "        save_to_h5file(channel_data, split_file_name, paths.sorting, ext='.hdf5')\n",
    "        print('\\tsaved channel: {}'.format(split_file_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
