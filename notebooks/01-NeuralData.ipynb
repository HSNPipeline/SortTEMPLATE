{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Data\n",
    "\n",
    "Check and explore the neural data for a single-unit project,\n",
    "\n",
    "This notebook covers loading data, preparing metadata, getting micro-LFP data, and splitting channels ready for sorting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# EXTRA STUFF FOR DEALING WITH MICRO LFPS\n",
    "#import scipy.io as sio\n",
    "#from scipy.signal import butter, resample, filtfilt\n",
    "#from scipy.fftpack import next_fast_len\n",
    "#import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import convnwb functions\n",
    "from convnwb.io import get_files, load_config, save_json, load_json\n",
    "from convnwb.paths import Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add brPY to path\n",
    "import sys\n",
    "br_path = '/home1/tom.donoghue/tools/brPY'\n",
    "sys.path.append(br_path)\n",
    "from brpylib import NsxFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the project path\n",
    "project_path = '/data12/jacobs_lab/BAU01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set session information\n",
    "SUBJ = {\n",
    "    'subject' : 'UT202014',\n",
    "    'experiment' : 'T3', \n",
    "    'session' : 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which site the subject is from\n",
    "#site = 'Baylor'\n",
    "site = 'Utah'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create database structure for the current file\n",
    "data_paths = Paths(project_path, **SUBJ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get & Check Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of available neural data files\n",
    "data_paths.get_files('neural')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available ns5 files\n",
    "data_files = data_paths.get_files('neural', select='ns5')\n",
    "data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data file to process\n",
    "data_file = data_files[0]\n",
    "data_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data Files\n",
    "\n",
    "Notes (to finish):\n",
    "- generalizing to ns5 or ns6 files\n",
    "- working if there is more than one NSP data file\n",
    "- Baylor: selecting the correct sheet from the excel sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the Nsx file \n",
    "nsxfile = NsxFile(str(data_paths.neural / data_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data \n",
    "nsp_data = nsxfile.getdata()\n",
    "nsxfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out the the ephys data, then rename remaining info\n",
    "data = nsp_data.pop('data')\n",
    "params = nsp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data shape\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check NSP information\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check params information\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(params['elec_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Write out metadata parameters\n",
    "# save_json(params, 'params.json', folder=db.sorting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload params info\n",
    "#params = load_json('params', folder=db.sorting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio Sync Pulses\n",
    "\n",
    "Audio sync channels: typically the NSP 1 file, with 11 channels, has audio sync pulses on 1th channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(12, 4))\n",
    "plt.plot(data[1, 0:10000000])\n",
    "#plt.plot(data[1, 20000000:30000000])\n",
    "#plt.plot(data[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define name for the audio sync file\n",
    "audio_sync_name = 'audio_sync_pulses.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save out audio channel\n",
    "# file = h5py.File(data_paths.alignment / audio_sync_name, \"w\")\n",
    "# file.create_dataset('data', data=data[1, :], dtype='<i2')\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Channel Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check electrode IDs that are in the loaded params file and in the electrodes sheet\n",
    "matching_eids = [eid for eid in params['elec_ids'] if eid in electrodes.channel_index.values]\n",
    "matching_eids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data by channels and write into hdf5 files\n",
    "print('\\n\\nSPLITTING CHANNEL FILES\\n\\n')\n",
    "for ix, electrode in enumerate(params['elec_ids']):\n",
    "\n",
    "    if electrode in electrodes.channel_index:\n",
    "        \n",
    "        print('  splitting electrode file: {}'.format(electrode))\n",
    "\n",
    "#         # Save out HDF5 of microdata        \n",
    "#         file = h5py.File(db.split_files / 'chan_{}.hdf5'.format(electrode), \"w\")\n",
    "#         file.create_dataset('data', data=data[ix, :], dtype='<i2')\n",
    "#         file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUFF FOR ABOVE LOOP FOR SAVING OUT MICRO LFP TRACES\n",
    "\n",
    "#         ## Pre-process and save out the micro-wire LFP\n",
    "#         rfs = 500\n",
    "#         fc = 250\n",
    "#         filt_ord = 4\n",
    "\n",
    "#         # Do a lowpass filter (250 Hz) on the LFP data\n",
    "#         [b_vals, a_vals] = butter(filt_ord, fc / (fs / 2), 'low')\n",
    "#         filted = filtfilt(b_vals, a_vals, data[ix, :])\n",
    "\n",
    "#         # Then downsample it to 500 Hz \n",
    "#         pad = np.ones([next_fast_len(len(filted)) - len(filted)])\n",
    "#         lfp = resample(np.append(filted, pad), int(len(np.append(filted, pad)) / (fs / rfs)))\n",
    "#         lfp = lfp[:-int(len(pad) / (fs / rfs))]\n",
    "\n",
    "#         # TODO: This might change soon! \n",
    "#         joblib.dump(lfp, f'{directories['micro_lfp']}/chan{electrode}.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the blackrock code\n",
    "# nsxfile.savesubsetnsx(elec_ids=[electrode], file_suffix='chan_{}'.format(electrode))\n",
    "# Matfile: This is redundant with HDF5 \n",
    "# data_as_dict = {'data': data[ix, :].astype('double'), 'fs':30000}\n",
    "# sio.savemat(\"{}_chan{}.mat\".format(path, electrode), data_as_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MISC EXTRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # UT registered data: \n",
    "# # channel_map_file = '/home1/salman.qasim/T3_Data/UT202014/Registered/ChannelMap.mat'\n",
    "# electrode_file = '/home1/salman.qasim/T3_Data/UT202014/Registered/Electrodes.mat'\n",
    "# f = h5py.File(electrode_file, 'r')\n",
    "\n",
    "# np.array(f['ElecXYZMNIRaw'])[0, :].shape\n",
    "\n",
    "# pd.read_csv('/home1/salman.qasim/T3_Data/UT202014/UT202014labels.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
